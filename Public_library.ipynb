{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMvgBoBKs57h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/drive/MyDrive/Assessment 2(Programming)/books_1.Best_Books_Ever.csv'\n",
        "books_df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "books_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering the dataset for books in foreign languages (English)\n",
        "foreign_language_books_df = books_df[books_df['language'] == 'English']"
      ],
      "metadata": {
        "id": "2xsr_bNjNR-O"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# Function to check if the description suggests the book is suitable for children\n",
        "def is_description_suitable(description):\n",
        "    if not isinstance(description, str):\n",
        "        return False  # If the description is missing or not a string, we'll consider it unsuitable\n",
        "\n",
        "    # List of keywords that might indicate unsuitability for young children\n",
        "    unsuitable_keywords = ['Mature', 'Violence', 'Sexual', 'Explicit', 'Horror']\n",
        "\n",
        "    # Basic check for the presence of these keywords\n",
        "    if any(re.search(keyword, description, re.IGNORECASE) for keyword in unsuitable_keywords):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "# Apply the updated function to further filter books\n",
        "suitable_children_books_df = foreign_language_books_df[foreign_language_books_df['description'].apply(is_description_suitable)]\n",
        "\n",
        "# Display filtered dataset\n",
        "suitable_children_books_df\n"
      ],
      "metadata": {
        "id": "SUczZoS5N9Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter books based on a high rating(>=4.0) and enough people commented(>=200000) and  a high enough positive rating(>=95.0)\n",
        "highly_rated_children_books_df = suitable_children_books_df[(suitable_children_books_df['rating'] >= 4.0) & (suitable_children_books_df['numRatings'] >= 200000) &(suitable_children_books_df['likedPercent'] >= 95.0)]\n",
        "# Display the dataset with highly selected books\n",
        "highly_rated_children_books_df\n"
      ],
      "metadata": {
        "id": "CRVFcd6sPy5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Considering books with a known price and below a certain threshold (e.g. $20)\n",
        "# Convert the 'price' column to numeric values\n",
        "# This step will handle any non-numeric values by converting them to NaN\n",
        "highly_rated_children_books_df['price'] = pd.to_numeric(highly_rated_children_books_df['price'], errors='coerce')\n",
        "\n",
        "# Run this filter with the corrected price column\n",
        "affordable_books = highly_rated_children_books_df[(highly_rated_children_books_df['price'] <= 20)]\n",
        "\n",
        "# Display the final selection of books\n",
        "affordable_books\n",
        "# affordable_books(164 rows Ã— 25 columns)"
      ],
      "metadata": {
        "id": "ww7gkS7CV0zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# At this step I need to see the complete list, so I need to print it out\n",
        "affordable_books.to_csv('affordable_books_selection.csv', index=False)"
      ],
      "metadata": {
        "id": "UB9y2BlVGTFF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Here I made a file myself and manually entered the Lexile value of each book\n",
        "# Considering that this is a dataset from the United States, I think it is reasonable to further screen the books according to the American Lexile criteria.\n",
        "# But I didn't find any relevant data sets online, so I manually entered the book names filtered out in the previous step on the Lexile website, and finally made a table(Lexile_score.csv).\n",
        "file_path_2 = '/content/drive/MyDrive/Assessment 2(Programming)/Lexile_score.csv'\n",
        "Lexile_df = pd.read_csv(file_path_2)\n",
        "\n",
        "# Merge the two tables using the common 'title' column\n",
        "merge_df = pd.merge(affordable_books, Lexile_df, on='title', how='left')\n",
        "\n",
        "# Because it is a manual search, some books do not have corresponding Lexile values (NaN).\n",
        "cleaned_merged_books_df = merge_df.dropna(subset=['Lexile'])\n",
        "\n",
        "cleaned_merged_books_df.to_csv('cleaned_merged_books.csv', index=False)"
      ],
      "metadata": {
        "id": "ytc56lDlewnC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Visualization 1 Top10 Most rated books\n",
        "top10_rated_books = cleaned_merged_books_df.nlargest(10, 'numRatings')\n",
        "plt.figure(figsize =(12,8))\n",
        "sns.barplot(x='numRatings', y='title', data= top10_rated_books, palette=\"viridis\")\n",
        "plt.title('Top10 Most Rated Books')\n",
        "plt.xlabel('Number of Ratings')\n",
        "plt.ylabel('Books title')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X8BoL10D6eIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization 2 Top10 Genres distribution\n",
        "import ast\n",
        "from collections import Counter\n",
        "genre_list = []\n",
        "for genres in cleaned_merged_books_df['genres']:\n",
        "  genres = ast.literal_eval(genres)\n",
        "  genre_list.extend(genres)\n",
        "genre_counts = Counter(genre_list)\n",
        "top_genres = dict(genre_counts.most_common(10))\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.pie(top_genres.values(), labels=top_genres.keys(), autopct='%1.1f%%', startangle=140)\n",
        "plt.title('Top 10 Genres Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P0X9WKkwDzVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization 3 Average ratings by Top10 Authors\n",
        "author_counts = cleaned_merged_books_df['author'].value_counts()\n",
        "authors_with_multiple_books = author_counts[author_counts > 1].index\n",
        "filtered_books = books_df[books_df['author'].isin(authors_with_multiple_books)]\n",
        "average_ratings = filtered_books.groupby('author')['rating'].mean().sort_values(ascending=False).head(10)\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x=average_ratings.values, y=average_ratings.index, palette=\"mako\")\n",
        "plt.title('Average Rating by Author (Top 10 Authors with Multiple Books)')\n",
        "plt.xlabel('Average Rating')\n",
        "plt.ylabel('Author')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mD_hqdCjFPjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization 4 Distribution of Book Ratings\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(cleaned_merged_books_df['rating'], bins=30, kde=False, color='skyblue')\n",
        "plt.title('Distribution of Book Ratings')\n",
        "plt.xlabel('Ratings')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wEKoiiYKGTMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization 5 Distribution of Books' price\n",
        "cleaned_merged_books_df['price'] = pd.to_numeric(cleaned_merged_books_df['price'], errors='coerce')\n",
        "books_with_price = cleaned_merged_books_df.dropna(subset=['price'])\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(books_with_price['price'], bins=30, color='purple', kde=True)\n",
        "plt.title('Price Distribution of Books')\n",
        "plt.xlabel('Price (USD)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tV2L-aApHWaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization 6: Book Ratings & Number of Ratings\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=cleaned_merged_books_df, x='rating', y='numRatings', alpha=0.5)\n",
        "plt.title('Book Ratings & Number of Ratings')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Number of Ratings')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d27W8eMnHznr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}